{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c27cb0f5",
   "metadata": {},
   "source": [
    "# Task 2: Bayesian Change Point Detection\n",
    "\n",
    "## Objective\n",
    "Detect structural breaks in the Brent oil price time series using a Bayesian Change Point model. We will identify the date of significant changes in the mean of log returns and associate them with historical events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f53180",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append(os.path.abspath(os.path.join('..')))\n",
    "\n",
    "from src.data_loader import load_data, calculate_log_returns\n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "print(f\"PyMC Version: {pm.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb080b1",
   "metadata": {},
   "source": [
    "## 1. Data Preparation\n",
    "Load the data and calculate log returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259c8da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "file_path = '../data/BrentOilPrices.csv'\n",
    "df = load_data(file_path)\n",
    "df = calculate_log_returns(df)\n",
    "\n",
    "# Visualize Log Returns\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(df.index, df['Log_Returns'], alpha=0.6)\n",
    "plt.title('Brent Oil Price Log Returns')\n",
    "plt.ylabel('Log Return')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99af3843",
   "metadata": {},
   "source": [
    "## 2. Bayesian Change Point Model\n",
    "We model log returns as two Gaussian distributions separated by $\\tau$.\n",
    "\n",
    "$$\\mu_t = \\text{switch}(\\tau \\ge idx, \\mu_2, \\mu_1)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7164907c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for PyMC\n",
    "y = df['Log_Returns'].values\n",
    "n_samples = len(y)\n",
    "idx = np.arange(n_samples)\n",
    "\n",
    "with pm.Model() as model:\n",
    "    tau = pm.DiscreteUniform(\"tau\", lower=0, upper=n_samples - 1)\n",
    "    mu1 = pm.Normal(\"mu1\", mu=0, sigma=0.1)\n",
    "    mu2 = pm.Normal(\"mu2\", mu=0, sigma=0.1)\n",
    "    sigma = pm.HalfNormal(\"sigma\", sigma=0.1)\n",
    "    mu = pm.math.switch(tau >= idx, mu2, mu1)\n",
    "    obs = pm.Normal(\"obs\", mu=mu, sigma=sigma, observed=y)\n",
    "    trace = pm.sample(500, tune=500, cores=1, return_inferencedata=True, progressbar=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impact-analysis",
   "metadata": {},
   "source": [
    "## 3. Quantitative Impact Analysis\n",
    "\n",
    "Now we quantify the statistical shift between the two identified regimes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impact-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "tau_mean = int(trace.posterior['tau'].values.mean())\n",
    "mu1_mean = float(trace.posterior['mu1'].values.mean())\n",
    "mu2_mean = float(trace.posterior['mu2'].values.mean())\n",
    "sigma_mean = float(trace.posterior['sigma'].values.mean())\n",
    "change_date = df.index[tau_mean]\n",
    "\n",
    "print(f\"Structural Change Identified at: {change_date.date()}\")\n",
    "print(f\"Mean Log-Return (Regime 1): {mu1_mean:.6f}\")\n",
    "print(f\"Mean Log-Return (Regime 2): {mu2_mean:.6f}\")\n",
    "print(f\"Absolute Shift in Mean: {abs(mu2_mean - mu1_mean):.6f}\")\n",
    "print(f\"Posterior Residual Volatility (Sigma): {sigma_mean:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "causal-narrative",
   "metadata": {},
   "source": [
    "## 4. Causal Narratives & Event Association\n",
    "We link our detected change point to the structured events dataset to understand the plausible drivers of this structural shift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "narrative-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "events_df = pd.read_csv('../data/events_data.csv')\n",
    "events_df['Date'] = pd.to_datetime(events_df['Date'])\n",
    "events_df['Days_Diff'] = (events_df['Date'] - change_date).dt.days.abs()\n",
    "key_event = events_df.sort_values('Days_Diff').iloc[0]\n",
    "\n",
    "print(f\"Detected Change Point: {change_date.date()}\")\n",
    "print(f\"Closest Event: {key_event['Event']} ({key_event['Date'].date()})\")\n",
    "print(f\"Description: {key_event['Description']}\")\n",
    "\n",
    "print(\"\\n--- Causal Hypothesis ---\")\n",
    "if \"COVID\" in key_event['Event'] or \"Pandemic\" in key_event['Event']:\n",
    "    print(\"H1: The change point identifies the demand destruction peak where global lockdowns led to an unprecedented collapse in crude demand.\")\n",
    "    print(\"The model detects a shift in return behavior as markets moved from stability into extreme negative volatility and subsequent policy-driven recovery.\")\n",
    "elif \"Gulf War\" in key_event['Event']:\n",
    "    print(\"H1: The change point aligns with the supply-shock expectation at the start of the conflict, as speculators priced in the risk of sustained Middle Eastern disruption.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
